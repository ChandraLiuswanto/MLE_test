{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIHxYoalspiN",
        "outputId": "de3f3890-51b2-4c77-eaf0-5935c09fe515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import scipy.io, os, torch\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "if os.getcwd()=='/content':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    file_loc = ('gdrive/MyDrive/colab/ex4data1.mat')\n",
        "else:\n",
        "    file_loc = 'ex4data1.mat'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "mat = scipy.io.loadmat(file_loc)\n",
        "X = mat['X']\n",
        "y = mat['y']\n",
        "y = np.where(y==10,0,y)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "U6xzPiaDspiP"
      },
      "outputs": [],
      "source": [
        "X_a = X.reshape(-1,20,20, order='F')\n",
        "X_b = torch.from_numpy(X_a.astype(np.float32)).to(device)\n",
        "y_b = (torch.from_numpy(y.astype(int))).to(device)\n",
        "dataset = TensorDataset(X_b, y_b)\n",
        "\n",
        "test_ratio = 0.2  # 20% data split into test dataset\n",
        "n_sample = X_a.shape[0]\n",
        "test_size = int(n_sample * test_ratio)\n",
        "train_size = n_sample - test_size\n",
        "train_ds, test_ds = random_split(dataset,[train_size, test_size])\n",
        "train_dataloader = DataLoader(train_ds, batch_size=train_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=test_size)\n",
        "for X_C in train_dataloader:\n",
        "    X_train = X_C[0].view(-1,1,20,20).to(device)\n",
        "    y_train = X_C[1].type(torch.LongTensor).flatten().to(device)\n",
        "for X_D in test_dataloader:\n",
        "    X_test = X_D[0].view(-1,1,20,20).to(device)\n",
        "    y_test = X_D[1].type(torch.LongTensor).flatten().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "BuSNvKoyspiS"
      },
      "outputs": [],
      "source": [
        "class CNN_model(nn.Module):\n",
        "    def __init__(self,input_channel,classes):\n",
        "        super(CNN_model,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_channel, out_channels=20,kernel_size=(5, 5))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t# initialize second set of CONV => RELU => POOL layers\n",
        "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t# initialize first (and only) set of FC => RELU layers\n",
        "        self.fc1 = nn.Linear(in_features=200, out_features=50)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        # initialize our softmax classifier\n",
        "        self.fc2 = nn.Linear(in_features=50, out_features=classes)\n",
        "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self,x_val):\n",
        "        z = self.conv1(x_val)\n",
        "        z = self.relu1(z)\n",
        "        z = self.maxpool1(z)\n",
        "        z = self.conv2(z)\n",
        "        z = self.relu2(z)\n",
        "        z = self.maxpool2(z)\n",
        "        z = torch.flatten(z,1)\n",
        "        z = self.fc1(z)\n",
        "        z = self.relu3(z)\n",
        "        z = self.fc2(z)\n",
        "        z = self.logSoftmax(z)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46qR6o0tspiT"
      },
      "outputs": [],
      "source": [
        "model = CNN_model(1,10).to(device)\n",
        "loss = nn.NLLLoss()\n",
        "epoch = int(1e5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0ZWfxzkpspiU",
        "outputId": "c6df515f-fd2f-4a08-ea00-cba6e127ad5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 0 : Loss = 29.77477, accuracy train = 0.025 %, test = 0.300 %\n",
            "Epoch number 50 : Loss = 1.15282, accuracy train = 59.000 %, test = 58.500 %\n",
            "Epoch number 100 : Loss = 0.49188, accuracy train = 85.675 %, test = 85.700 %\n",
            "Epoch number 150 : Loss = 0.30965, accuracy train = 91.275 %, test = 90.900 %\n",
            "Epoch number 200 : Loss = 0.22227, accuracy train = 93.525 %, test = 93.600 %\n",
            "Epoch number 250 : Loss = 0.16605, accuracy train = 95.450 %, test = 94.500 %\n",
            "Epoch number 300 : Loss = 0.12732, accuracy train = 96.350 %, test = 96.100 %\n",
            "Epoch number 350 : Loss = 0.10030, accuracy train = 97.275 %, test = 96.300 %\n",
            "Epoch number 400 : Loss = 0.08124, accuracy train = 97.875 %, test = 96.500 %\n",
            "Epoch number 450 : Loss = 0.06699, accuracy train = 98.125 %, test = 96.600 %\n",
            "Epoch number 500 : Loss = 0.05590, accuracy train = 98.650 %, test = 96.800 %\n",
            "Epoch number 550 : Loss = 0.04699, accuracy train = 98.900 %, test = 97.200 %\n",
            "Epoch number 600 : Loss = 0.03971, accuracy train = 99.125 %, test = 97.300 %\n",
            "Epoch number 650 : Loss = 0.03368, accuracy train = 99.350 %, test = 97.300 %\n",
            "Epoch number 700 : Loss = 0.02860, accuracy train = 99.550 %, test = 97.400 %\n",
            "Epoch number 750 : Loss = 0.02430, accuracy train = 99.650 %, test = 97.400 %\n",
            "Epoch number 800 : Loss = 0.02063, accuracy train = 99.775 %, test = 97.400 %\n",
            "Epoch number 850 : Loss = 0.01751, accuracy train = 99.825 %, test = 97.400 %\n",
            "Epoch number 900 : Loss = 0.01489, accuracy train = 99.850 %, test = 97.400 %\n",
            "Epoch number 950 : Loss = 0.01270, accuracy train = 99.925 %, test = 97.400 %\n",
            "Epoch number 1000 : Loss = 0.01089, accuracy train = 99.950 %, test = 97.500 %\n",
            "Epoch number 1050 : Loss = 0.00941, accuracy train = 99.975 %, test = 97.500 %\n",
            "Epoch number 1100 : Loss = 0.00817, accuracy train = 100.000 %, test = 97.500 %\n",
            "Epoch number 1150 : Loss = 0.00714, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1200 : Loss = 0.00627, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1250 : Loss = 0.00553, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1300 : Loss = 0.00490, accuracy train = 100.000 %, test = 97.500 %\n",
            "Epoch number 1350 : Loss = 0.00437, accuracy train = 100.000 %, test = 97.400 %\n",
            "Epoch number 1400 : Loss = 0.00392, accuracy train = 100.000 %, test = 97.400 %\n",
            "Epoch number 1450 : Loss = 0.00352, accuracy train = 100.000 %, test = 97.400 %\n",
            "Epoch number 1500 : Loss = 0.00318, accuracy train = 100.000 %, test = 97.400 %\n",
            "Epoch number 1550 : Loss = 0.00289, accuracy train = 100.000 %, test = 97.500 %\n",
            "Epoch number 1600 : Loss = 0.00263, accuracy train = 100.000 %, test = 97.500 %\n",
            "Epoch number 1650 : Loss = 0.00240, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1700 : Loss = 0.00220, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1750 : Loss = 0.00202, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1800 : Loss = 0.00186, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1850 : Loss = 0.00172, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1900 : Loss = 0.00160, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 1950 : Loss = 0.00148, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 2000 : Loss = 0.00138, accuracy train = 100.000 %, test = 97.600 %\n",
            "Epoch number 2050 : Loss = 0.00129, accuracy train = 100.000 %, test = 97.700 %\n",
            "Epoch number 2100 : Loss = 0.00120, accuracy train = 100.000 %, test = 97.700 %\n",
            "Epoch number 2150 : Loss = 0.00113, accuracy train = 100.000 %, test = 97.700 %\n",
            "Epoch number 2200 : Loss = 0.00106, accuracy train = 100.000 %, test = 97.700 %\n",
            "Epoch number 2250 : Loss = 0.00099, accuracy train = 100.000 %, test = 97.700 %\n",
            "Epoch number 2300 : Loss = 0.00093, accuracy train = 100.000 %, test = 97.700 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-f642e1173284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mtest_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0macc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch number {i} : Loss = {J:.5f}, accuracy train = {acc:.3f} %, test = {acc_test:.3f} %'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
        "for i in range(epoch):\n",
        "    out = model(X_train)\n",
        "    J = loss(out,y_train)\n",
        "    J.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if i%50==0:\n",
        "        with torch.no_grad():\n",
        "            test_out = model(X_test)\n",
        "            acc_test = ((torch.argmax(test_out,dim=1).flatten()==y_test).sum().item()) * (100/1000)\n",
        "            acc = ((torch.argmax(out,dim=1).flatten()==y_train).sum().item()) * (100/4000)\n",
        "        print(f'Epoch number {i} : Loss = {J:.5f}, accuracy train = {acc:.3f} %, test = {acc_test:.3f} %')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'model.pt')"
      ],
      "metadata": {
        "id": "mhDgcRjX8fry",
        "outputId": "e3b725bf-8f0d-47b7-ce74-0a081e21aeee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-02c40aef1510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: save() got an unexpected keyword argument 'map_location'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main_CNN.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "294ce20df86c934b8e6934fc8826ec74c86f3a7103def11d1ee6e795248841c1"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('ML_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}