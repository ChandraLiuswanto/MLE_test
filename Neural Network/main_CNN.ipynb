{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "mat = scipy.io.loadmat('ex4data1.mat')\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "\n",
    "#plt.imshow(img_out(X,0))\n",
    "y_a = np.zeros((10,5000)).astype('int32')\n",
    "y_temp = np.where(y==10,0,y)\n",
    "for i in range(5000):\n",
    "    y_a[y_temp[i],i] = 1\n",
    "y_a = np.r_[y_a[1:,:], y_a[0,:].reshape(1,-1)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = X.reshape(-1,20,20, order='F')\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X_b = torch.from_numpy(X_a.astype(np.float32)).to(device)\n",
    "y_b = (torch.from_numpy(y_a.astype(np.float32))).to(device)\n",
    "dataset = TensorDataset(X_b, y_b)\n",
    "\n",
    "test_ratio = 0.2  # 20% data split into test dataset\n",
    "n_sample = X_a.shape[0]\n",
    "test_size = int(n_sample * test_ratio)\n",
    "train_size = n_sample - test_size\n",
    "train_ds, test_ds = random_split(dataset,[train_size, test_size])\n",
    "train_dataloader = DataLoader(train_ds, batch_size=train_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=test_size)\n",
    "for X_C in train_dataloader:\n",
    "    X_train = X_C[0].view(-1,1,20,20)\n",
    "    y_train = X_C[1]\n",
    "for X_D in test_dataloader:\n",
    "    X_test = X_D[0].view(-1,1,20,20)\n",
    "    y_test = X_D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 20, 16, 16])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax = nn.Conv2d(in_channels=1,out_channels=20,kernel_size=5)\n",
    "ax(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self,input_channel,classes):\n",
    "        super(CNN_model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channel, out_channels=20,kernel_size=(5, 5))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\t# initialize second set of CONV => RELU => POOL layers\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\t# initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = nn.Linear(in_features=200, out_features=50)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x_val):\n",
    "        z = self.conv1(x_val)\n",
    "        z = self.relu1(z)\n",
    "        z = self.maxpool1(z)\n",
    "        z = self.conv2(z)\n",
    "        z = self.relu2(z)\n",
    "        z = self.maxpool2(z)\n",
    "        z = torch.flatten(z,1)\n",
    "        z = self.fc1(z)\n",
    "        z = self.relu3(z)\n",
    "        z = self.fc2(z)\n",
    "        z = self.sigmoid(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_model(1,10)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epoch = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0 : Loss = 1.4690, accuracy 405\n",
      "Epoch number 10 : Loss = 1.4671, accuracy 406\n",
      "Epoch number 20 : Loss = 1.4671, accuracy 406\n",
      "Epoch number 30 : Loss = 1.4670, accuracy 406\n",
      "Epoch number 40 : Loss = 1.4670, accuracy 405\n",
      "Epoch number 50 : Loss = 1.4670, accuracy 405\n",
      "Epoch number 60 : Loss = 1.4670, accuracy 405\n",
      "Epoch number 70 : Loss = 1.4670, accuracy 405\n",
      "Epoch number 80 : Loss = 1.4670, accuracy 405\n",
      "Epoch number 90 : Loss = 1.4670, accuracy 405\n",
      "Epoch number 100 : Loss = 1.4670, accuracy 405\n",
      "Epoch number 110 : Loss = 1.4670, accuracy 405\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chand\\Desktop\\JOB HUNT\\learn\\MLE_test\\Neural Network\\main_CNN.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/JOB%20HUNT/learn/MLE_test/Neural%20Network/main_CNN.ipynb#ch0000005?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m model(X_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/JOB%20HUNT/learn/MLE_test/Neural%20Network/main_CNN.ipynb#ch0000005?line=3'>4</a>\u001b[0m J \u001b[39m=\u001b[39m loss(out,y_train)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/JOB%20HUNT/learn/MLE_test/Neural%20Network/main_CNN.ipynb#ch0000005?line=4'>5</a>\u001b[0m J\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/JOB%20HUNT/learn/MLE_test/Neural%20Network/main_CNN.ipynb#ch0000005?line=5'>6</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/chand/Desktop/JOB%20HUNT/learn/MLE_test/Neural%20Network/main_CNN.ipynb#ch0000005?line=6'>7</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\chand\\anaconda3\\envs\\ML_env\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\chand\\anaconda3\\envs\\ML_env\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/chand/anaconda3/envs/ML_env/lib/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.5e-3)\n",
    "for i in range(epoch):\n",
    "    out = model(X_train)\n",
    "    J = loss(out,y_train)\n",
    "    J.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if i%10==0:\n",
    "        print(f'Epoch number {i} : Loss = {J:.4f}, accuracy {(torch.argmax(out,dim=1)==torch.argmax(y_train)).sum().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(out,dim=1)==torch.argmax(y_train)).sum().item()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "294ce20df86c934b8e6934fc8826ec74c86f3a7103def11d1ee6e795248841c1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ML_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
