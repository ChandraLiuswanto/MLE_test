{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library and dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer()\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the dataset to tensor and split train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_a = torch.from_numpy(X.astype(np.float32)).to(device)\n",
    "y_a = (torch.from_numpy(y.astype(np.float32))).view(-1,1).to(device)\n",
    "\n",
    "dataset = TensorDataset(X_a, y_a)\n",
    "\n",
    "test_ratio = 0.2  # 20% data split into test dataset\n",
    "n_sample,n_feature = X_a.shape\n",
    "test_size = int(n_sample * test_ratio)\n",
    "train_size = n_sample - test_size\n",
    "train_ds, test_ds = random_split(dataset,[train_size, test_size])\n",
    "train_dataloader = DataLoader(train_ds, batch_size=train_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a NN model with 2 hidden layer\n",
    "first layer = 10\n",
    "\n",
    "second layer = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticNN, self).__init__()\n",
    "        layer1_out = 10\n",
    "        layer2_out = 5\n",
    "        self.layer1 = nn.Linear(30,layer1_out,bias=True)\n",
    "        self.layer2 = nn.Linear(layer1_out,layer2_out,bias=True)\n",
    "        self.output = nn.Linear(layer2_out,1,bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = torch.relu(self.layer1(x))\n",
    "        z = torch.relu(self.layer2(z))\n",
    "        z = torch.sigmoid(self.output(z))\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Train, and Save the model\n",
    "loss model = Binary Cross Entropy\n",
    "\n",
    "Optimizer = Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Cost = 0.1367, train acc = 97.5877%, test acc = 95.5154%\n",
      "Epoch 10: Cost = 0.2344, train acc = 94.5175%, test acc = 98.2503%\n",
      "Epoch 20: Cost = 0.1697, train acc = 96.4912%, test acc = 99.2701%\n",
      "Epoch 30: Cost = 0.1265, train acc = 97.1491%, test acc = 99.2481%\n",
      "Epoch 40: Cost = 0.1120, train acc = 97.1491%, test acc = 99.0231%\n",
      "Epoch 50: Cost = 0.1134, train acc = 97.3684%, test acc = 99.1146%\n",
      "Epoch 60: Cost = 0.1102, train acc = 97.5877%, test acc = 99.2165%\n",
      "Epoch 70: Cost = 0.1090, train acc = 97.1491%, test acc = 99.1269%\n",
      "Epoch 80: Cost = 0.1084, train acc = 97.3684%, test acc = 99.1576%\n",
      "Epoch 90: Cost = 0.1078, train acc = 97.8070%, test acc = 99.1213%\n"
     ]
    }
   ],
   "source": [
    "model = LogisticNN().to(device)\n",
    "if os.path.exists('breast_cancer.pt'):\n",
    "    model.load_state_dict(torch.load('breast_cancer.pt'))\n",
    "    epoch_max = 100\n",
    "    report = 10\n",
    "else:\n",
    "    epoch_max = 10000\n",
    "    report = 500\n",
    "loss = nn.BCELoss()\n",
    "rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=rate,weight_decay=1e-3)\n",
    "for i in range(epoch_max):\n",
    "    for x_batch_train, y_batch_train in train_dataloader:\n",
    "        z = model(x_batch_train)\n",
    "        J = loss(z,y_batch_train)\n",
    "        J.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if i % report  == 0:\n",
    "        with torch.no_grad():\n",
    "            acc = (1-(z.round()-y_batch_train).abs().mean().item())*100\n",
    "            for x_batch_test, y_batch_test in test_dataloader:\n",
    "                zx = model(x_batch_test)\n",
    "                acc_test = (1-(zx-y_batch_test).abs().mean().item())*100\n",
    "        print(f'Epoch {i}: Cost = {J.item():.4f}, train acc = {acc:.4f}%, test acc = {acc_test:.4f}%')\n",
    "\n",
    "torch.save(model.state_dict(),'breast_cancer.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report of the neural network training\n",
    "createing confusion matrix, accuracy, recall, precision, and F1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result show for all value that    \n",
      " True positive = 353    \n",
      " False positive = 7    \n",
      " False Negative = 4    \n",
      " True negative = 205    \n",
      "\n",
      " Accuracy = 98.06678%    \n",
      " Precision = 98.05556%    \n",
      " Recall = 98.87955%    \n",
      " F1 score = 0.9847    \n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_val = np.zeros(y.shape).astype(int)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # first change data from gpu memory to cpu memory \n",
    "    # Change to numpy, vectorize, rounding\n",
    "    z = model(X_a).cpu().detach().numpy().flatten()\n",
    "\n",
    "#change to interger with 0.5 as reference \n",
    "z = z>=0.5  \n",
    "for i, val in enumerate(y):\n",
    "    if y[i] == z[i]: #True value\n",
    "\n",
    "        if y[i]:\n",
    "            confusion_matrix_val[i] = 1 # True Positive\n",
    "        else:\n",
    "            confusion_matrix_val[i] = 4 # True Negative\n",
    "    else:\n",
    "        if y[i]:\n",
    "            confusion_matrix_val[i] = 3 # False negative, predicted negative but true value positive\n",
    "        else:\n",
    "            confusion_matrix_val[i] = 2\n",
    "        \n",
    "\n",
    "confusion_mat = np.array([0,0,0,0]) # TP, FP, FN, TN\n",
    "for i in range(4):\n",
    "    confusion_mat[i] = np.count_nonzero((confusion_matrix_val==(i+1))*1)\n",
    "precision = confusion_mat[0]/(confusion_mat[0]+confusion_mat[1])\n",
    "recall = confusion_mat[0]/(confusion_mat[0]+confusion_mat[2])\n",
    "F1 = 2*precision*recall/(precision+recall)\n",
    "accuracy = (confusion_mat[0]+confusion_mat[3]) /confusion_mat.sum()\n",
    "\n",
    "print(f'The result show for all value that\\\n",
    "    \\n True positive = {confusion_mat[0]}\\\n",
    "    \\n False positive = {confusion_mat[1]}\\\n",
    "    \\n False Negative = {confusion_mat[2]}\\\n",
    "    \\n True negative = {confusion_mat[3]}\\\n",
    "    \\n\\n Accuracy = {accuracy*100:.5f}%\\\n",
    "    \\n Precision = {precision*100:.5f}%\\\n",
    "    \\n Recall = {recall*100:.5f}%\\\n",
    "    \\n F1 score = {F1:.4f}    ')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
